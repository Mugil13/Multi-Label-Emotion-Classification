{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QgaIyqy1Bjb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, get_scheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, classification_report\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/train/eng.csv\")\n",
        "\n",
        "# Extract features and labels\n",
        "texts = df[\"text\"].tolist()\n",
        "labels = df[[\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]].values\n",
        "\n",
        "# Split into training and testing sets\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Tokenization using Roberta tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")"
      ],
      "metadata": {
        "id": "AB38_h0F1V0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_texts(texts, tokenizer, max_len=256):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        max_length=max_len,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "train_encodings = tokenize_texts(texts_train, tokenizer, max_len=256)\n",
        "test_encodings = tokenize_texts(texts_test, tokenizer, max_len=256)"
      ],
      "metadata": {
        "id": "Jw4_p3ua1V3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "train_dataset = EmotionDataset(train_encodings, labels_train)\n",
        "test_dataset = EmotionDataset(test_encodings, labels_test)"
      ],
      "metadata": {
        "id": "BIk4u5xx1bzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained Roberta model\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-large\",\n",
        "    num_labels=5,\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "qSK5KP_m1b2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function without class weights\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "loss_fn = BCEWithLogitsLoss()\n",
        "\n",
        "# Set up dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "num_training_steps = len(train_loader) * 3  # 3 epochs\n",
        "lr_scheduler = get_scheduler(\"cosine\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "# Mixed precision training\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "id": "kWVXTQPr1vvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(3):  # 3 epochs\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            loss = loss_fn(logits, batch[\"labels\"])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        loop.set_description(f\"Epoch {epoch}\")\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []"
      ],
      "metadata": {
        "id": "samPWKEA1zg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.sigmoid(logits).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "# Optimize thresholds per label\n",
        "optimal_thresholds = []\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "for i in range(all_labels.shape[1]):\n",
        "    precision, recall, thresholds = precision_recall_curve(all_labels[:, i], all_preds[:, i])\n",
        "    f1_scores = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "    optimal_idx = np.argmax(f1_scores)\n",
        "    optimal_thresholds.append(thresholds[optimal_idx])\n",
        "\n",
        "# Apply optimized thresholds\n",
        "all_preds_bin = (all_preds > np.array(optimal_thresholds)).astype(int)"
      ],
      "metadata": {
        "id": "wGwC7qxC14nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print metrics\n",
        "accuracy = (all_preds_bin == all_labels).mean()\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(classification_report(all_labels, all_preds_bin, target_names=[\"Anger\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]))"
      ],
      "metadata": {
        "id": "1BQyb4M61zkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr  # Importing pearsonr for correlation calculation\n",
        "\n",
        "# Load the training dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/train/eng.csv\")  # Adjust path\n",
        "texts = df[\"text\"].tolist()\n",
        "labels = df[[\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]].values\n",
        "\n",
        "# Split into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Tokenization using Roberta tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")\n",
        "\n",
        "def tokenize_texts(texts, tokenizer, max_len=256):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        max_length=max_len,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "train_encodings = tokenize_texts(texts_train, tokenizer, max_len=256)\n",
        "test_encodings = tokenize_texts(texts_test, tokenizer, max_len=256)"
      ],
      "metadata": {
        "id": "kda5tP8V2BqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "train_dataset = EmotionDataset(train_encodings, labels_train.astype(np.float32))\n",
        "test_dataset = EmotionDataset(test_encodings, labels_test.astype(np.float32))\n",
        "\n",
        "# Load pre-trained Roberta model and modify for regression\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-large\",\n",
        "    num_labels=5  # Number of emotions\n",
        ")\n",
        "model.classifier.out_proj = torch.nn.Linear(model.classifier.out_proj.in_features, 5)\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "Lwx7kZIt2Ftl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "from torch.nn import MSELoss\n",
        "from transformers import AdamW, get_scheduler\n",
        "loss_fn = MSELoss()\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Learning rate scheduler\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "num_training_steps = len(train_loader) * 3  # 3 epochs\n",
        "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "# Mixed precision training\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(3):  # Train for 3 epochs\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch in loop:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            loss = loss_fn(logits, batch[\"labels\"])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        loop.set_description(f\"Epoch {epoch}\")\n",
        "        loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "id": "rrFcomaJ2JrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluate the model on the Test Split ---\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        all_preds.extend(logits.cpu().numpy())\n",
        "        all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# --- Early Correction: Set any negative predictions to 0 ---\n",
        "all_preds[all_preds < 0] = 0  # Set negative values to 0\n",
        "\n",
        "# Convert the predictions to whole numbers (integers) by rounding\n",
        "all_preds = np.round(all_preds).astype(int)  # Round and convert to integers\n",
        "\n",
        "# --- Calculate and Print Metrics ---\n",
        "# Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(all_labels, all_preds, multioutput='raw_values')\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(all_labels, all_preds, multioutput='raw_values')\n",
        "\n",
        "# R-squared (R2) score\n",
        "r2 = r2_score(all_labels, all_preds, multioutput='raw_values')\n",
        "\n",
        "# Pearson Correlation Coefficient\n",
        "pearson_corrs = []\n",
        "for i in range(all_labels.shape[1]):  # Iterate over each emotion dimension\n",
        "    corr, _ = pearsonr(all_labels[:, i], all_preds[:, i])\n",
        "    pearson_corrs.append(corr)\n",
        "\n",
        "pearson_corrs = np.array(pearson_corrs)\n",
        "\n",
        "# Print metrics including Pearson correlation\n",
        "print(\"--- Emotion-wise Metrics ---\")\n",
        "for i, emotion in enumerate([\"Anger\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]):\n",
        "    print(f\"{emotion}: MSE={mse[i]:.4f}, MAE={mae[i]:.4f}, R2={r2[i]:.4f}, Pearson={pearson_corrs[i]:.4f}\")\n",
        "\n",
        "print(\"\\n--- Overall Metrics ---\")\n",
        "print(f\"Mean MSE: {mse.mean():.4f}, Mean MAE: {mae.mean():.4f}, Mean R2: {r2.mean():.4f}, Mean Pearson: {pearson_corrs.mean():.4f}\")"
      ],
      "metadata": {
        "id": "-tDSNWN-2N6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prediction on Data from `test.csv` ---\n",
        "# Load the test dataset for prediction (Separate test data)\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/test/eng.csv\")  # Adjust path to your test CSV\n",
        "texts_test_csv = test_df[\"text\"].tolist()  # The texts in the test.csv for prediction\n",
        "\n",
        "# Tokenize the test texts\n",
        "test_encodings_csv = tokenize_texts(texts_test_csv, tokenizer, max_len=256)\n",
        "\n",
        "# Create test dataset (no labels needed for prediction)\n",
        "test_dataset_csv = EmotionDataset(test_encodings_csv, np.zeros((len(texts_test_csv), 5)))  # Dummy labels for prediction\n",
        "test_loader_csv = DataLoader(test_dataset_csv, batch_size=16)\n",
        "\n",
        "# Predict using the trained model\n",
        "model.eval()\n",
        "all_preds_csv = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader_csv:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        all_preds_csv.extend(logits.cpu().numpy())\n",
        "\n",
        "# Convert predictions to numpy array for test.csv\n",
        "all_preds_csv = np.array(all_preds_csv)\n",
        "\n",
        "# If any emotion value is less than 0, set it to 0\n",
        "all_preds_csv[all_preds_csv < 0] = 0\n",
        "\n",
        "# Convert to whole numbers (integers) by rounding and then converting\n",
        "all_preds_csv = np.round(all_preds_csv).astype(int)\n",
        "\n",
        "# Create DataFrame with correct column order\n",
        "output_df = pd.DataFrame(all_preds_csv, columns=[\"Anger\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"])\n",
        "output_df.insert(0, \"id\", test_df[\"id\"])  # Insert ID at the first column\n",
        "\n",
        "# Save predictions to CSV file\n",
        "output_path = \"/content/drive/MyDrive/pred_eng_1.csv\"  # Update with your preferred path\n",
        "output_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_path}\")"
      ],
      "metadata": {
        "id": "C5e7SuW52RH_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}